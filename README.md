# ğŸ” RedditExtractor

**A professional, proxy-enabled Reddit scraping API. Deploy to Railway in one click.**

[![Deploy on Railway](https://railway.app/button.svg)](https://railway.app/template/your-template-id)

---

## ğŸ¯ About RedditExtractor

RedditExtractor is a powerful, production-ready API for scraping Reddit. It comes with full proxy support, a flexible API for fetching posts, comments, and user data, and is designed for seamless integration with n8n, Zapier, or any custom workflow.

**This is the first tool in the Extractor Suite** - a series of professional scraping APIs designed for the modern automation stack.

## ğŸš€ Quick Start

1. **Deploy to Railway** - Click the button above
2. **Set Environment Variables** (optional - for proxy support):
   ```env
   PROXY_HOST=your-proxy-host
   PROXY_PORT=your-proxy-port
   PROXY_USERNAME=your-username
   PROXY_PASSWORD=your-password
   ```
3. **Start Scraping** - Your API is ready at `https://your-app.railway.app`

## ğŸ“‹ Features

- ğŸ¯ **URL-based & Search-based Scraping** - Scrape specific subreddits, users, or search across Reddit
- ğŸ”„ **Proxy Support** - Built-in proxy integration for production use
- ğŸ“Š **Structured JSON Responses** - Clean, consistent API responses
- ğŸ”§ **25+ Parameters** - Comprehensive control over scraping behavior
- âš¡ **Automation Ready** - Perfect for n8n, Zapier, and custom workflows
- ğŸ“ˆ **Built-in Documentation** - Interactive docs at `/docs`
- ğŸš¨ **Error Handling** - Proper error codes and detailed responses
- ğŸ›¡ï¸ **Input Validation** - Comprehensive parameter validation

## ğŸ”Œ API Endpoints

### Main Scraping Endpoint
```http
POST /api/scrape
Content-Type: application/json
```

### Health & Status
```http
GET /health          # API health check
GET /test-proxy      # Proxy connectivity test
GET /docs           # Interactive documentation
```

## ğŸ’¡ Usage Examples

### 1. Scrape Subreddit Posts
```json
{
  "startUrls": ["https://reddit.com/r/python"],
  "searchForPosts": true,
  "maxItems": 50,
  "sortSearch": "hot",
  "filterByDate": "week"
}
```

### 2. Search Across Reddit
```json
{
  "searchTerm": "machine learning",
  "searchForPosts": true,
  "sortSearch": "relevance",
  "filterByDate": "month",
  "maxItems": 200
}
```

### 3. User-Specific Scraping
```json
{
  "startUrls": ["https://reddit.com/user/someuser"],
  "searchForPosts": true,
  "skipComments": true,
  "maxItems": 100
}
```

## ğŸ“– Complete Parameter Reference

### Input Sources (Choose One)
- **`startUrls`** - Array of Reddit URLs to scrape
- **`searchTerm`** - Search query for Reddit-wide search

### Content Control
- **`searchForPosts`** - Include posts (default: true)
- **`searchForComments`** - Include comments (default: true)
- **`skipComments`** - Skip comment scraping for performance
- **`includeNSFW`** - Include NSFW content (default: false)

### Sorting & Filtering
- **`sortSearch`** - Sort order: "hot", "new", "top", "rising", "relevance"
- **`filterByDate`** - Time filter: "hour", "day", "week", "month", "year", "all"
- **`postDateLimit`** - ISO date string to filter posts after date

### Limits & Pagination
- **`maxItems`** - Maximum items to return (1-10000)
- **`postsPerPage`** - Posts per page (1-100)
- **`commentsPerPage`** - Comments per page (1-100)

## ğŸ“Š Response Format

### Success Response
```json
{
  "success": true,
  "data": {
    "posts": [...],
    "comments": [...],
    "users": [...],
    "communities": [...]
  },
  "metadata": {
    "totalItems": 150,
    "itemsReturned": 100,
    "requestParams": {...},
    "scrapedAt": "2025-07-16T17:00:07Z",
    "executionTime": "2.3s"
  },
  "errors": []
}
```

### Error Response
```json
{
  "success": false,
  "data": null,
  "metadata": {
    "requestParams": {...},
    "scrapedAt": "2025-07-16T17:00:07Z"
  },
  "errors": [
    {
      "code": "PROXY_ERROR",
      "message": "Proxy connection failed",
      "details": "Connection timeout after 10 seconds"
    }
  ]
}
```

## ğŸ”— Automation Integration

RedditExtractor is designed for seamless integration with automation platforms:

### n8n HTTP Request Node
```javascript
Method: POST
URL: https://your-app.railway.app/api/scrape
Headers: Content-Type: application/json
Body: {
  "startUrls": ["https://reddit.com/r/{{$json.subreddit}}"],
  "maxItems": {{$json.limit}},
  "sortSearch": "{{$json.sort}}"
}
```

### Zapier Webhooks
```javascript
URL: https://your-app.railway.app/api/scrape
Method: POST
Headers: Content-Type: application/json
Data: {
  "searchTerm": "{{inputData.query}}",
  "maxItems": 50,
  "sortSearch": "relevance"
}
```

The structured response format makes it easy to process results in subsequent workflow nodes.

## ğŸ› ï¸ Local Development

### Prerequisites
- Python 3.8+
- pip or uv package manager

### Installation
```bash
git clone https://github.com/your-username/reddit-extractor.git
cd reddit-extractor
pip install -r requirements.txt
```

### Environment Variables
```env
# Optional: Proxy configuration
PROXY_HOST=your-proxy-host
PROXY_PORT=your-proxy-port
PROXY_USERNAME=your-username
PROXY_PASSWORD=your-password

# Server configuration
PORT=8000
```

### Run Locally
```bash
python app.py
```

API will be available at `http://localhost:8000`

## ğŸš¨ Error Codes

| Code | Description | Recommended Action |
|------|-------------|-------------------|
| `PROXY_ERROR` | Proxy connection issues | Check proxy configuration and network connectivity |
| `REDDIT_BLOCKED` | Reddit blocking requests | Use a proxy or wait before retrying |
| `INVALID_PARAMS` | Parameter validation failed | Check parameter values and types |
| `TIMEOUT` | Request timeout | Try reducing maxItems or check network connection |
| `RATE_LIMITED` | Reddit rate limiting | Wait a few minutes before making another request |
| `INVALID_RESPONSE` | Invalid response from Reddit | The requested content may not exist or be available |

## ğŸ“ Project Structure

```
reddit-extractor/
â”œâ”€â”€ app.py                 # Main Flask application
â”œâ”€â”€ requirements.txt       # Python dependencies
â”œâ”€â”€ Procfile              # Railway deployment config
â”œâ”€â”€ src/
â”‚   â””â”€â”€ yars/
â”‚       â”œâ”€â”€ yars.py       # Core scraping logic
â”‚       â”œâ”€â”€ validator.py  # Parameter validation
â”‚       â”œâ”€â”€ url_parser.py # URL parsing utilities
â”‚       â”œâ”€â”€ sessions.py   # Session management
â”‚       â””â”€â”€ utils.py      # Utility functions
â””â”€â”€ example/
    â””â”€â”€ example.py        # Usage examples
```

## ğŸ”’ Security & Best Practices

- âœ… **Proxy Support** - Built-in proxy integration for IP rotation
- âœ… **Rate Limiting** - Respects Reddit's rate limits
- âœ… **Input Validation** - Comprehensive parameter validation
- âœ… **Error Handling** - Graceful error handling and logging
- âœ… **No API Keys** - Uses Reddit's public JSON endpoints

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Add tests if applicable
5. Submit a pull request

## ğŸ“„ License

MIT License - see [LICENSE](LICENSE) for details.

## ğŸ†˜ Support

- ğŸ“– **Documentation**: Visit `/docs` on your deployed instance
- ğŸ› **Issues**: [GitHub Issues](https://github.com/your-username/reddit-extractor/issues)
- ğŸ’¬ **Discussions**: [GitHub Discussions](https://github.com/your-username/reddit-extractor/discussions)

## ğŸš€ Deploy to Railway

[![Deploy on Railway](https://railway.app/button.svg)](https://railway.app/template/your-template-id)

---

## ğŸ™ Acknowledgements

RedditExtractor builds upon the solid foundation of the open-source project **YARS (Yet Another Reddit Scraper)**. We've heavily modified and enhanced it to create a professional, deployable API product.

---

**Built with â¤ï¸ for the modern automation stack**